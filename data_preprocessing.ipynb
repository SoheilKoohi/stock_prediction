{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "data_preprocessing.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mP-a_FiS7KF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader \n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data.sampler import SequentialSampler\n",
        "from torch.utils.data import Sampler\n",
        "from sklearn.preprocessing import scale"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0jyYQw1S7KM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_default_device():\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device(\"cuda\")\n",
        "    else:\n",
        "        return torch.device(\"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uO8TrDDBXXbI",
        "colab_type": "code",
        "outputId": "e0f07c82-8af5-4c54-d2a9-46f3a68224cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrcekdqPS7KQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = get_default_device()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KninQwzMS7KT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_device(data,device):\n",
        "    if isinstance(data,(list,tuple)):\n",
        "        return [to_device(x,device) for x in data]\n",
        "    return data.to(device,non_blocking = True)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pTZ_josS7KX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class StockDataset(Dataset):\n",
        "    def __init__(self,dir_path,start_year = 2002,end_year = 2017,window_size = 12):\n",
        "        self.dir_path = dir_path\n",
        "        self.start_year = start_year\n",
        "        self.end_year = end_year\n",
        "        self.window_size = window_size\n",
        "        self.data = self._load_data(self.dir_path,self.start_year,self.end_year)\n",
        "#         self.preprocessed_data = self._preprocess(self.data)\n",
        "        self.x,self.y = self._create_features_and_labels(self.data,self.window_size)\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "    def _load_data(self,dir_path,start_year,end_year):\n",
        "        col_name = [\"date\",\"time\",\"open\",\"high\",\"low\",\"close\",\"volume\"]\n",
        "        df_full = pd.DataFrame(columns = col_name)\n",
        "        for root, dirs, files in os.walk(dir_path):\n",
        "            for file in files:\n",
        "                year = int(file.split(\".\")[0].split(\"_\")[-1])\n",
        "                if (file.endswith(\".csv\") and year >= start_year \n",
        "                and year <= end_year):\n",
        "                    df = pd.read_csv(os.path.join(root,file),names = col_name)\n",
        "                    df_full = pd.concat([df_full,df])\n",
        "                    print(\"Stock data of year {0} loaded\".format(str(year)))\n",
        "        df_full.reset_index(inplace = True)\n",
        "        return df_full\n",
        "      \n",
        "      \n",
        "      \n",
        "    \n",
        "    \n",
        "    def _create_features_and_labels(self,df,window_size):\n",
        "       \n",
        "        n = df.shape[0]\n",
        "        x_array = np.empty(shape = (n - window_size,window_size))\n",
        "        y_array = np.empty(shape = (n - window_size,1))\n",
        "        close_index = df.close\n",
        "        for i in tqdm(range(n-window_size),desc =  \"Creating Features and Labels...\"):\n",
        "            x_array[i] = close_index.iloc[i:i+window_size].values\n",
        "            y_array[i] = close_index.iloc[i + window_size]\n",
        "        x_array = scale(x_array)\n",
        "        y_array = scale(y_array)\n",
        "        return x_array,y_array\n",
        "    \n",
        "    def __getitem__(self,idx):\n",
        "        return self.x[idx],self.y[idx]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.x.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAgOftjxS7Ka",
        "colab_type": "code",
        "outputId": "9afb86b5-ebde-43a7-e64b-1db81723973c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "PATH = \"/content/drive/My Drive/stock_data/EURGBP\"\n",
        "data = StockDataset(dir_path=PATH,start_year=2017)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating Features and Labels...:   0%|          | 716/370241 [00:00<00:51, 7147.40it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Stock data of year 2017 loaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Creating Features and Labels...: 100%|██████████| 370241/370241 [00:34<00:00, 10781.97it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdUTCBQ_S7Kf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TestSampler(Sampler):\n",
        "    r\"\"\"Samples elements sequentially, always in the same order.\n",
        "\n",
        "    Arguments:\n",
        "        data_source (Dataset): dataset to sample from\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data_source):\n",
        "        self.data_source = data_source\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter(range(self.data_source[0],self.data_source[-1] + 1))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_source)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJK7EVK5S7Kj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_split = .8\n",
        "dataset_size = len(data)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(train_split * dataset_size))\n",
        "train_indices, test_indices = indices[:split], indices[split:]\n",
        "train_sampler = SequentialSampler(train_indices)\n",
        "test_sampler = TestSampler(test_indices)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVfBAgL3S7Kn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl = DataLoader(data,batch_size=64,sampler=train_sampler,num_workers=8)\n",
        "test_dl = DataLoader(data,batch_size=64,sampler=test_sampler,num_workers=8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-adriOYgDAqy",
        "colab_type": "code",
        "outputId": "75b255e2-7ed5-44c7-e541-3f6184b54103",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for xb,yb in test_dl:\n",
        "  print(xb.device)\n",
        "  break"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SPqglt0S7Kq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DeviceDataLoader():\n",
        "    def __init__(self,dl,device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "    def __iter__(self):\n",
        "        for batch in self.dl:\n",
        "            yield to_device(batch,self.device)\n",
        "    def __len__(self):\n",
        "        return len(self.dl)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yclz9qitS7Ku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl = DeviceDataLoader(train_dl,device)\n",
        "test_dl = DeviceDataLoader(test_dl,device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Vi-RU_8DQMC",
        "colab_type": "code",
        "outputId": "b4572552-2925-4e40-af10-71d5324c07c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for xb,yb in test_dl:\n",
        "  print(xb.device)\n",
        "  break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_jcDspKS7Kx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        # Hidden dimensions\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # Number of hidden layers\n",
        "        self.layer_dim = layer_dim\n",
        "\n",
        "        # Building your LSTM\n",
        "        # batch_first=True causes input/output tensors to be of shape\n",
        "        # (batch_dim, seq_dim, feature_dim)\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim,batch_first = True)\n",
        "\n",
        "        # Readout layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.relu = nn.Sigmoid()\n",
        "    def forward(self, x):\n",
        "        # Initialize hidden state with zeros\n",
        "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
        "\n",
        "        # Initialize cell state\n",
        "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
        "        x = x[...,None].float()\n",
        "        # 12 time steps\n",
        "        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
        "        # If we don't, we'll backprop all the way to the start even after going through another batch\n",
        "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
        "        # Index hidden state of last time step\n",
        "        # out.size() --> 12,\n",
        "        # out[:, -1, :] --> 100, 100 --> just want last time step hidden states! \n",
        "        out = self.fc(out[:,-1, :]) \n",
        "        # out.size() --> 100, 10\n",
        "        return self.relu(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rR1EMYY4S7K1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = LSTMModel(input_dim = 1 , hidden_dim = 8, layer_dim = 1, output_dim = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXSN2HWSQbDi",
        "colab_type": "code",
        "outputId": "cdff7765-9447-4080-cb92-1c6fc0b4443b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "for t in model.parameters():\n",
        "  print(t.shape)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 1])\n",
            "torch.Size([32, 8])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "torch.Size([1, 8])\n",
            "torch.Size([1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCKOFcXmjJ6Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Train(train_dl,model,opt,loss_fn):\n",
        "  losses =[]\n",
        "  nums = []\n",
        "  model.train()\n",
        "  for xb,yb in train_dl:\n",
        "    preds = model(xb)\n",
        "    loss = loss_fn(preds,yb.float())\n",
        "  \n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "    losses.append(loss.item())\n",
        "    nums.append(len(xb))\n",
        "      \n",
        "      \n",
        "  total = np.sum(nums)\n",
        "  avg_loss = np.sum(np.multiply(losses,nums)) / total\n",
        "  \n",
        "  return avg_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Wigv9A2oxWV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Validation(test_dl,model,loss_fn):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    losses = []\n",
        "    nums = []\n",
        "    for xb,yb in test_dl:\n",
        "      preds = model(xb)\n",
        "      loss = loss_fn(preds,yb.float())\n",
        "      losses.append(loss.item())\n",
        "      nums.append(len(xb))\n",
        "    total = np.sum(nums)\n",
        "    avg_loss = np.sum(np.multiply(losses,nums)) / total\n",
        "    return avg_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucV8_3IGQVAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(epoch,train_dl,test_dl,model,opt,loss_fn):\n",
        "  \n",
        "  \n",
        "  total_loss_train = []\n",
        "  total_loss_test = []\n",
        "  opt\n",
        "  \n",
        "  \n",
        "  for i in range(epoch):\n",
        "    \n",
        "    #training Phase\n",
        "    train_loss = Train(train_dl,model,opt,loss_fn)\n",
        "    total_loss_train.append(train_loss)\n",
        "    \n",
        "    #test phase\n",
        "    val_loss = Validation(test_dl,model,loss_fn)\n",
        "    total_loss_test.append(val_loss)\n",
        "    print(\"Epoch [{}/{}], train_loss: {:.4f}, test_loss: {:.4f}\".format(i+1,epoch,\n",
        "                                                                       train_loss,\n",
        "                                                                       val_loss))\n",
        "  return total_loss_train,total_loss_test\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KsVyovVzsdr",
        "colab_type": "code",
        "outputId": "7311bb97-a7ca-4ecc-bc13-6a73cba48771",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "optimizer = Adam(model.parameters(),lr = 0.001)\n",
        "loss_fn = nn.MSELoss()\n",
        "loss_train,loss_test = fit(10,train_dl,test_dl,model,optimizer,loss_fn)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/10], train_loss: 0.7842, test_loss: 0.0090\n",
            "Epoch [2/10], train_loss: 0.7142, test_loss: 0.0121\n",
            "Epoch [3/10], train_loss: 0.7149, test_loss: 0.0199\n",
            "Epoch [4/10], train_loss: 0.7140, test_loss: 0.0047\n",
            "Epoch [5/10], train_loss: 0.7136, test_loss: 0.0023\n",
            "Epoch [6/10], train_loss: 0.7134, test_loss: 0.0020\n",
            "Epoch [7/10], train_loss: 0.7134, test_loss: 0.0020\n",
            "Epoch [8/10], train_loss: 0.7133, test_loss: 0.0019\n",
            "Epoch [9/10], train_loss: 0.7133, test_loss: 0.0017\n",
            "Epoch [10/10], train_loss: 0.7133, test_loss: 0.0016\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMLQ5T4J2Akh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "e25940ca-41e0-408d-d955-360033216236"
      },
      "source": [
        "loss_test"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3107427896462443,\n",
              " 0.3107427896462443,\n",
              " 0.3107427896462443,\n",
              " 0.3107427896462443,\n",
              " 0.3107427896462443,\n",
              " 0.3107427896462443,\n",
              " 0.3107427896462443,\n",
              " 0.3107427896462443,\n",
              " 0.3107427896462443,\n",
              " 0.3107427896462443]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_kO2tUBBZez",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c61e4934-2ef6-4fac-c5b2-ae638e9cc491"
      },
      "source": [
        "(preds.numpy())"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.8411585 ],\n",
              "       [0.84197557],\n",
              "       [0.84277093],\n",
              "       [0.84246993],\n",
              "       [0.842355  ],\n",
              "       [0.8423331 ],\n",
              "       [0.8423337 ],\n",
              "       [0.8429625 ],\n",
              "       [0.8420489 ],\n",
              "       [0.8416215 ],\n",
              "       [0.8416122 ],\n",
              "       [0.84166217],\n",
              "       [0.84106445],\n",
              "       [0.840611  ],\n",
              "       [0.83997   ],\n",
              "       [0.83930755],\n",
              "       [0.8369018 ],\n",
              "       [0.83877707],\n",
              "       [0.8400159 ],\n",
              "       [0.84026456],\n",
              "       [0.84069467],\n",
              "       [0.84056973],\n",
              "       [0.84011555],\n",
              "       [0.8407862 ],\n",
              "       [0.84103096],\n",
              "       [0.84215057],\n",
              "       [0.84164643],\n",
              "       [0.842602  ],\n",
              "       [0.84285915],\n",
              "       [0.8408108 ],\n",
              "       [0.83959174],\n",
              "       [0.8418094 ],\n",
              "       [0.8432685 ],\n",
              "       [0.83897495],\n",
              "       [0.8390993 ],\n",
              "       [0.8381301 ],\n",
              "       [0.83958924],\n",
              "       [0.8412931 ],\n",
              "       [0.8421016 ],\n",
              "       [0.8405628 ],\n",
              "       [0.8407264 ],\n",
              "       [0.8406888 ],\n",
              "       [0.842571  ],\n",
              "       [0.840335  ],\n",
              "       [0.83887434],\n",
              "       [0.8377795 ],\n",
              "       [0.8363962 ],\n",
              "       [0.8377278 ],\n",
              "       [0.83821285],\n",
              "       [0.8369992 ],\n",
              "       [0.8379172 ],\n",
              "       [0.8382522 ],\n",
              "       [0.83800864],\n",
              "       [0.83605146],\n",
              "       [0.83577645],\n",
              "       [0.8346306 ],\n",
              "       [0.8347992 ],\n",
              "       [0.83632934],\n",
              "       [0.8350811 ],\n",
              "       [0.8345572 ],\n",
              "       [0.8355489 ],\n",
              "       [0.837008  ],\n",
              "       [0.8389224 ],\n",
              "       [0.8375585 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TE-czxkO2Wk0",
        "colab_type": "code",
        "outputId": "4571a6ed-d80b-4841-9989-910a0e122532",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "i = 0\n",
        "for xb,yb in test_dl:\n",
        "  if i > 0:\n",
        "    with torch.no_grad():\n",
        "      preds = model(yb)\n",
        "      print(np.abs(preds - yb))\n",
        "      break\n",
        "  i+=1"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.0164],\n",
            "        [0.0167],\n",
            "        [0.0164],\n",
            "        [0.0161],\n",
            "        [0.0171],\n",
            "        [0.0170],\n",
            "        [0.0155],\n",
            "        [0.0155],\n",
            "        [0.0161],\n",
            "        [0.0163],\n",
            "        [0.0163],\n",
            "        [0.0158],\n",
            "        [0.0158],\n",
            "        [0.0146],\n",
            "        [0.0146],\n",
            "        [0.0146],\n",
            "        [0.0149],\n",
            "        [0.0151],\n",
            "        [0.0148],\n",
            "        [0.0152],\n",
            "        [0.0160],\n",
            "        [0.0139],\n",
            "        [0.0141],\n",
            "        [0.0144],\n",
            "        [0.0144],\n",
            "        [0.0136],\n",
            "        [0.0139],\n",
            "        [0.0139],\n",
            "        [0.0158],\n",
            "        [0.0158],\n",
            "        [0.0152],\n",
            "        [0.0154],\n",
            "        [0.0138],\n",
            "        [0.0151],\n",
            "        [0.0146],\n",
            "        [0.0145],\n",
            "        [0.0149],\n",
            "        [0.0145],\n",
            "        [0.0168],\n",
            "        [0.0163],\n",
            "        [0.0160],\n",
            "        [0.0160],\n",
            "        [0.0158],\n",
            "        [0.0160],\n",
            "        [0.0154],\n",
            "        [0.0165],\n",
            "        [0.0160],\n",
            "        [0.0146],\n",
            "        [0.0155],\n",
            "        [0.0155],\n",
            "        [0.0154],\n",
            "        [0.0160],\n",
            "        [0.0164],\n",
            "        [0.0161],\n",
            "        [0.0163],\n",
            "        [0.0151],\n",
            "        [0.0160],\n",
            "        [0.0160],\n",
            "        [0.0161],\n",
            "        [0.0160],\n",
            "        [0.0168],\n",
            "        [0.0171],\n",
            "        [0.0173],\n",
            "        [0.0185]], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yA85Tm62Dv39",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cbf9a296-a83c-484e-a0c0-0be0640697d5"
      },
      "source": [
        "xb,yb = next(iter(test_dl))\n",
        "with torch.no_grad():\n",
        "  print(model(xb))\n",
        "  print(yb)"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.7838],\n",
            "        [0.7827],\n",
            "        [0.7817],\n",
            "        [0.7779],\n",
            "        [0.7753],\n",
            "        [0.7758],\n",
            "        [0.7756],\n",
            "        [0.7750],\n",
            "        [0.7743],\n",
            "        [0.7733],\n",
            "        [0.7754],\n",
            "        [0.7770],\n",
            "        [0.7779],\n",
            "        [0.7791],\n",
            "        [0.7782],\n",
            "        [0.7769],\n",
            "        [0.7769],\n",
            "        [0.7771],\n",
            "        [0.7744],\n",
            "        [0.7731],\n",
            "        [0.7722],\n",
            "        [0.7724],\n",
            "        [0.7733],\n",
            "        [0.7750],\n",
            "        [0.7766],\n",
            "        [0.7782],\n",
            "        [0.7781],\n",
            "        [0.7771],\n",
            "        [0.7759],\n",
            "        [0.7741],\n",
            "        [0.7713],\n",
            "        [0.7695],\n",
            "        [0.7702],\n",
            "        [0.7694],\n",
            "        [0.7693],\n",
            "        [0.7690],\n",
            "        [0.7679],\n",
            "        [0.7683],\n",
            "        [0.7686],\n",
            "        [0.7691],\n",
            "        [0.7705],\n",
            "        [0.7700],\n",
            "        [0.7693],\n",
            "        [0.7696],\n",
            "        [0.7709],\n",
            "        [0.7707],\n",
            "        [0.7736],\n",
            "        [0.7749],\n",
            "        [0.7760],\n",
            "        [0.7766],\n",
            "        [0.7767],\n",
            "        [0.7744],\n",
            "        [0.7732],\n",
            "        [0.7711],\n",
            "        [0.7699],\n",
            "        [0.7678],\n",
            "        [0.7673],\n",
            "        [0.7672],\n",
            "        [0.7660],\n",
            "        [0.7656],\n",
            "        [0.7672],\n",
            "        [0.7695],\n",
            "        [0.7715],\n",
            "        [0.7727]])\n",
            "tensor([[0.7800],\n",
            "        [0.7791],\n",
            "        [0.7727],\n",
            "        [0.7713],\n",
            "        [0.7742],\n",
            "        [0.7727],\n",
            "        [0.7713],\n",
            "        [0.7703],\n",
            "        [0.7688],\n",
            "        [0.7732],\n",
            "        [0.7742],\n",
            "        [0.7742],\n",
            "        [0.7756],\n",
            "        [0.7732],\n",
            "        [0.7717],\n",
            "        [0.7732],\n",
            "        [0.7737],\n",
            "        [0.7683],\n",
            "        [0.7683],\n",
            "        [0.7678],\n",
            "        [0.7688],\n",
            "        [0.7698],\n",
            "        [0.7717],\n",
            "        [0.7732],\n",
            "        [0.7747],\n",
            "        [0.7732],\n",
            "        [0.7717],\n",
            "        [0.7708],\n",
            "        [0.7688],\n",
            "        [0.7654],\n",
            "        [0.7644],\n",
            "        [0.7669],\n",
            "        [0.7644],\n",
            "        [0.7644],\n",
            "        [0.7639],\n",
            "        [0.7620],\n",
            "        [0.7634],\n",
            "        [0.7634],\n",
            "        [0.7639],\n",
            "        [0.7659],\n",
            "        [0.7639],\n",
            "        [0.7630],\n",
            "        [0.7644],\n",
            "        [0.7664],\n",
            "        [0.7649],\n",
            "        [0.7703],\n",
            "        [0.7703],\n",
            "        [0.7713],\n",
            "        [0.7717],\n",
            "        [0.7717],\n",
            "        [0.7678],\n",
            "        [0.7678],\n",
            "        [0.7654],\n",
            "        [0.7649],\n",
            "        [0.7620],\n",
            "        [0.7625],\n",
            "        [0.7625],\n",
            "        [0.7600],\n",
            "        [0.7600],\n",
            "        [0.7630],\n",
            "        [0.7654],\n",
            "        [0.7669],\n",
            "        [0.7673],\n",
            "        [0.7693]], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}