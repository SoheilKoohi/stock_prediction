{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "data_preprocessing.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mP-a_FiS7KF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader \n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data.sampler import SequentialSampler\n",
        "from torch.utils.data import Sampler\n",
        "from sklearn.preprocessing import scale"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0jyYQw1S7KM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_default_device():\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device(\"cuda\")\n",
        "    else:\n",
        "        return torch.device(\"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uO8TrDDBXXbI",
        "colab_type": "code",
        "outputId": "411a9764-72de-4646-e9f6-865dc2459908",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrcekdqPS7KQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = get_default_device()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KninQwzMS7KT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_device(data,device):\n",
        "    if isinstance(data,(list,tuple)):\n",
        "        return [to_device(x,device) for x in data]\n",
        "    return data.to(device,non_blocking = True)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pTZ_josS7KX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class StockDataset(Dataset):\n",
        "    def __init__(self,dir_path,start_year = 2002,end_year = 2017,window_size = 12):\n",
        "        self.dir_path = dir_path\n",
        "        self.start_year = start_year\n",
        "        self.end_year = end_year\n",
        "        self.window_size = window_size\n",
        "        self.data = self._load_data(self.dir_path,self.start_year,self.end_year)\n",
        "#         self.preprocessed_data = self._preprocess(self.data)\n",
        "        self.x,self.y = self._create_features_and_labels(self.data,self.window_size)\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "    def _load_data(self,dir_path,start_year,end_year):\n",
        "        col_name = [\"date\",\"time\",\"open\",\"high\",\"low\",\"close\",\"volume\"]\n",
        "        df_full = pd.DataFrame(columns = col_name)\n",
        "        for root, dirs, files in os.walk(dir_path):\n",
        "            for file in files:\n",
        "                year = int(file.split(\".\")[0].split(\"_\")[-1])\n",
        "                if (file.endswith(\".csv\") and year >= start_year \n",
        "                and year <= end_year):\n",
        "                    df = pd.read_csv(os.path.join(root,file),names = col_name)\n",
        "                    df_full = pd.concat([df_full,df])\n",
        "                    print(\"Stock data of year {0} loaded\".format(str(year)))\n",
        "        df_full.reset_index(inplace = True)\n",
        "        return df_full\n",
        "      \n",
        "      \n",
        "      \n",
        "    \n",
        "    \n",
        "    def _create_features_and_labels(self,df,window_size):\n",
        "       \n",
        "        n = df.shape[0]\n",
        "        x_array = np.empty(shape = (n - window_size,window_size))\n",
        "        y_array = np.empty(shape = (n - window_size,1))\n",
        "        close_index = df.close\n",
        "        for i in tqdm(range(n-window_size),desc =  \"Creating Features and Labels...\"):\n",
        "            x_array[i] = close_index.iloc[i:i+window_size].values\n",
        "            y_array[i] = close_index.iloc[i + window_size]\n",
        "        x_array = scale(x_array)\n",
        "        y_array = scale(y_array)\n",
        "        return x_array,y_array\n",
        "    \n",
        "    def __getitem__(self,idx):\n",
        "        return self.x[idx],self.y[idx]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.x.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAgOftjxS7Ka",
        "colab_type": "code",
        "outputId": "9fbe4275-770f-4e2a-b2f7-dc9ae9e06c8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "PATH = \"/content/drive/My Drive/stock_data/EURGBP\"\n",
        "data = StockDataset(dir_path=PATH,start_year=2017,window_size=30)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating Features and Labels...:   0%|          | 704/370223 [00:00<00:52, 7033.55it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Stock data of year 2017 loaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Creating Features and Labels...: 100%|██████████| 370223/370223 [00:32<00:00, 11221.92it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdUTCBQ_S7Kf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TestSampler(Sampler):\n",
        "    r\"\"\"Samples elements sequentially, always in the same order.\n",
        "\n",
        "    Arguments:\n",
        "        data_source (Dataset): dataset to sample from\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data_source):\n",
        "        self.data_source = data_source\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter(range(self.data_source[0],self.data_source[-1] + 1))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_source)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJK7EVK5S7Kj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_split = .8\n",
        "dataset_size = len(data)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(train_split * dataset_size))\n",
        "train_indices, test_indices = indices[:split], indices[split:]\n",
        "train_sampler = SequentialSampler(train_indices)\n",
        "test_sampler = TestSampler(test_indices)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVfBAgL3S7Kn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl = DataLoader(data,batch_size=64,sampler=train_sampler,num_workers=8)\n",
        "test_dl = DataLoader(data,batch_size=64,sampler=test_sampler,num_workers=8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-adriOYgDAqy",
        "colab_type": "code",
        "outputId": "3c75f81c-ca81-41c2-bac8-7b521456e379",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for xb,yb in test_dl:\n",
        "  print(xb.device)\n",
        "  break"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SPqglt0S7Kq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DeviceDataLoader():\n",
        "    def __init__(self,dl,device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "    def __iter__(self):\n",
        "        for batch in self.dl:\n",
        "            yield to_device(batch,self.device)\n",
        "    def __len__(self):\n",
        "        return len(self.dl)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yclz9qitS7Ku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl = DeviceDataLoader(train_dl,device)\n",
        "test_dl = DeviceDataLoader(test_dl,device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Vi-RU_8DQMC",
        "colab_type": "code",
        "outputId": "b4572552-2925-4e40-af10-71d5324c07c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for xb,yb in test_dl:\n",
        "  print(xb.device)\n",
        "  break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_jcDspKS7Kx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        # Hidden dimensions\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # Number of hidden layers\n",
        "        self.layer_dim = layer_dim\n",
        "\n",
        "        # Building your LSTM\n",
        "        # batch_first=True causes input/output tensors to be of shape\n",
        "        # (batch_dim, seq_dim, feature_dim)\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim,batch_first = True)\n",
        "\n",
        "        # Readout layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.relu = nn.Sigmoid()\n",
        "    def forward(self, x):\n",
        "        # Initialize hidden state with zeros\n",
        "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
        "\n",
        "        # Initialize cell state\n",
        "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
        "        x = x[...,None].float()\n",
        "        # 12 time steps\n",
        "        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
        "        # If we don't, we'll backprop all the way to the start even after going through another batch\n",
        "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
        "        # Index hidden state of last time step\n",
        "        # out.size() --> 12,\n",
        "        # out[:, -1, :] --> 100, 100 --> just want last time step hidden states! \n",
        "        out = self.fc(out[:,-1, :]) \n",
        "        # out.size() --> 100, 10\n",
        "        return self.relu(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rR1EMYY4S7K1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = LSTMModel(input_dim = 1 , hidden_dim = 8, layer_dim = 1, output_dim = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXSN2HWSQbDi",
        "colab_type": "code",
        "outputId": "60971ec9-8d2b-4d83-c9ed-1961a867d9b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "for t in model.parameters():\n",
        "  print(t.shape)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 1])\n",
            "torch.Size([32, 8])\n",
            "torch.Size([32])\n",
            "torch.Size([32])\n",
            "torch.Size([1, 8])\n",
            "torch.Size([1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCKOFcXmjJ6Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Train(train_dl,model,opt,loss_fn):\n",
        "  losses =[]\n",
        "  nums = []\n",
        "  model.train()\n",
        "  for xb,yb in train_dl:\n",
        "    preds = model(xb)\n",
        "    loss = loss_fn(preds,yb.float())\n",
        "  \n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "    losses.append(loss.item())\n",
        "    nums.append(len(xb))\n",
        "      \n",
        "      \n",
        "  total = np.sum(nums)\n",
        "  avg_loss = np.sum(np.multiply(losses,nums)) / total\n",
        "  \n",
        "  return avg_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Wigv9A2oxWV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Validation(test_dl,model,loss_fn):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    losses = []\n",
        "    nums = []\n",
        "    for xb,yb in test_dl:\n",
        "      preds = model(xb)\n",
        "      loss = loss_fn(preds,yb.float())\n",
        "      losses.append(loss.item())\n",
        "      nums.append(len(xb))\n",
        "    total = np.sum(nums)\n",
        "    avg_loss = np.sum(np.multiply(losses,nums)) / total\n",
        "    return avg_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucV8_3IGQVAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(epoch,train_dl,test_dl,model,opt,loss_fn):\n",
        "  \n",
        "  \n",
        "  total_loss_train = []\n",
        "  total_loss_test = []\n",
        "  opt\n",
        "  \n",
        "  \n",
        "  for i in range(epoch):\n",
        "    \n",
        "    #training Phase\n",
        "    train_loss = Train(train_dl,model,opt,loss_fn)\n",
        "    total_loss_train.append(train_loss)\n",
        "    \n",
        "    #test phase\n",
        "    val_loss = Validation(test_dl,model,loss_fn)\n",
        "    total_loss_test.append(val_loss)\n",
        "    print(\"Epoch [{}/{}], train_loss: {:.4f}, test_loss: {:.4f}\".format(i+1,epoch,\n",
        "                                                                       train_loss,\n",
        "                                                                       val_loss))\n",
        "  return total_loss_train,total_loss_test\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KsVyovVzsdr",
        "colab_type": "code",
        "outputId": "c53e5d5f-01f3-456c-d10e-a5a8d3cfbffe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        }
      },
      "source": [
        "optimizer = Adam(model.parameters(),lr = 0.001)\n",
        "loss_fn = nn.MSELoss()\n",
        "loss_train,loss_test = fit(30,train_dl,test_dl,model,optimizer,loss_fn)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/30], train_loss: 0.7689, test_loss: 0.0036\n",
            "Epoch [2/30], train_loss: 0.7142, test_loss: 0.0036\n",
            "Epoch [3/30], train_loss: 0.7136, test_loss: 0.0026\n",
            "Epoch [4/30], train_loss: 0.7135, test_loss: 0.0023\n",
            "Epoch [5/30], train_loss: 0.7134, test_loss: 0.0022\n",
            "Epoch [6/30], train_loss: 0.7134, test_loss: 0.0019\n",
            "Epoch [7/30], train_loss: 0.7137, test_loss: 0.0018\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-b9c1ec4cec63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mloss_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_dl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-45-70a5f6e22adb>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epoch, train_dl, test_dl, model, opt, loss_fn)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#training Phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mtotal_loss_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-8b6980ffc03d>\u001b[0m in \u001b[0;36mTrain\u001b[0;34m(train_dl, model, opt, loss_fn)\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-41-1b5cec605017>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# We need to detach as we are doing truncated backpropagation through time (BPTT)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# If we don't, we'll backprop all the way to the start even after going through another batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;31m# Index hidden state of last time step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# out.size() --> 12,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_tensor\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0munsorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_impl\u001b[0;34m(self, input, hx, batch_sizes, max_batch_size, sorted_indices)\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m             result = _VF.lstm(input, hx, self._get_flat_weights(), self.bias, self.num_layers,\n\u001b[0;32m--> 526\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._get_flat_weights(), self.bias,\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yA85Tm62Dv39",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = np.empty(shape = (1,1))\n",
        "y_act = np.empty(shape = (1,1))\n",
        "for xb,yb in test_dl:\n",
        "  with torch.no_grad():\n",
        "    y_pred = np.concatenate([y_pred,model(xb).numpy()],axis = 0)\n",
        "    y_act = np.concatenate([y_act,yb.numpy()],axis = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PP4KdPpVRnTg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "98dec06a-9dde-4dd4-9b34-a621734cdde0"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig, ax = plt.subplots(figsize=(15,7), nrows=1, ncols=1 ) # create figure & 1 axis\n",
        "ax.plot(y_pred[-1000:-990],label = \"preds\")\n",
        "ax.plot(y_act[-1000:-990],color = \"red\",label = \"actual\")\n",
        "ax.legend(loc = \"upper right\")\n",
        "# fig.savefig('/content/drive/My Drive/stock_data/prediction.png')   # save the figure to file\n",
        "# plt.close(fig)\n",
        "# plt.figure(1)\n",
        "# plt.plot(y_pred[-2000:])\n",
        "# plt.plot(y_act[-2000:],color = \"red\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fc9f1028710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3AAAAGbCAYAAACF9nK/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1080x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}