{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "from torch import nn\n",
    "from torch.utils.data.sampler import SequentialSampler\n",
    "from torch.utils.data import Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_default_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(data,device):\n",
    "    if isinstance(data,(list,tuple)):\n",
    "        return [to_device(x,device) for x in data]\n",
    "    return data.to(device,non_blocking = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockDataset(Dataset):\n",
    "    def __init__(self,start_year = 2002,end_year = 2017,window_size = 12):\n",
    "        self.start_year = start_year\n",
    "        self.end_year = end_year\n",
    "        self.window_size = window_size\n",
    "        self.data = self._load_data(self.start_year,self.end_year)\n",
    "        self.x,self.y = self._create_features_and_labels(self.data,self.window_size)\n",
    "        \n",
    "    def _load_data(self,start_year,end_year):\n",
    "        col_name = [\"date\",\"time\",\"open\",\"high\",\"low\",\"close\",\"volume\"]\n",
    "        df_full = pd.DataFrame(columns = col_name)\n",
    "        for root, dirs, files in os.walk(\"/stock_prediction/stock_prediction/EURGBP/\"):\n",
    "            for file in files:\n",
    "                year = int(file.split(\".\")[0].split(\"_\")[-1])\n",
    "                if (file.endswith(\".csv\") and year >= start_year \n",
    "                and year <= end_year):\n",
    "                    df = pd.read_csv(os.path.join(root,file),names = col_name)\n",
    "                    df_full = pd.concat([df_full,df])\n",
    "                    print(\"Stock data of year {0} loaded\".format(str(year)))\n",
    "        df_full.reset_index(inplace = True)\n",
    "        return df_full\n",
    "    \n",
    "    \n",
    "    def _create_features_and_labels(self,df,window_size):\n",
    "        n = df.shape[0]\n",
    "        x_array = np.empty(shape = (n - window_size,window_size))\n",
    "        y_array = np.empty(shape = (n - window_size,1))\n",
    "        close_index = df.close\n",
    "        for i in tqdm(range(n-window_size),desc =  \"Creating Features and Labels...\"):\n",
    "            x_array[i] = close_index.iloc[i:i+window_size].values\n",
    "            y_array[i] = close_index.iloc[i + window_size]\n",
    "        return x_array,y_array\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.x[idx],self.y[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock data of year 2017 loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Features and Labels...: 100%|██████████████████████████████████████| 370241/370241 [00:14<00:00, 24725.67it/s]\n"
     ]
    }
   ],
   "source": [
    "data = StockDataset(start_year=2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestSampler(Sampler):\n",
    "    r\"\"\"Samples elements sequentially, always in the same order.\n",
    "\n",
    "    Arguments:\n",
    "        data_source (Dataset): dataset to sample from\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_source):\n",
    "        self.data_source = data_source\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(range(self.data_source[0],self.data_source[-1] + 1))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = .8\n",
    "dataset_size = len(data)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(train_split * dataset_size))\n",
    "train_indices, test_indices = indices[:split], indices[split:]\n",
    "train_sampler = SequentialSampler(train_indices)\n",
    "test_sampler = TestSampler(test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(data,batch_size=32,sampler=train_sampler)\n",
    "test_dl = DataLoader(data,batch_size=32,sampler=test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceDataLoader():\n",
    "    def __init__(self,dl,device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "    def __iter__(self):\n",
    "        for batch in self.dl:\n",
    "            yield to_device(batch,self.device)\n",
    "    def __len__(self):\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DeviceDataLoader(train_dl,device)\n",
    "test_dl = DeviceDataLoader(test_dl,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        # Hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Number of hidden layers\n",
    "        self.layer_dim = layer_dim\n",
    "\n",
    "        # Building your LSTM\n",
    "        # batch_first=True causes input/output tensors to be of shape\n",
    "        # (batch_dim, seq_dim, feature_dim)\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "\n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
    "\n",
    "        # Initialize cell state\n",
    "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
    "\n",
    "        # 28 time steps\n",
    "        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
    "        # If we don't, we'll backprop all the way to the start even after going through another batch\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "\n",
    "        # Index hidden state of last time step\n",
    "        # out.size() --> 100, 28, 100\n",
    "        # out[:, -1, :] --> 100, 100 --> just want last time step hidden states! \n",
    "        out = self.fc(out[-1, :, :]) \n",
    "        # out.size() --> 100, 10\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMModel(input_dim = 1 , hidden_dim = 8, layer_dim = 1, output_dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x.view((12,32,1)).float()).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
